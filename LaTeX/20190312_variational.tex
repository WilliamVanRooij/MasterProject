\section{Variational Inference}
When computing the posterior density of parameters according to observed data, we may want to simplify the computation by approximating the posterior density by a simpler density that does not involve the observed data. One way to do so is the variational inference, which gives an approximation of the posterior distribution as a result of an optimization problem that minimizes a measure of "closeness".\\
\newline
We suppose we have observations $x$ and parameters $z$, we are looking to approximate the posterior conditional distribution $p(z|x)$. Given a family of densities $\mathcal{D}$ over the parameters, we want to find the distribution $q \in \mathcal{D}$ that is the closest possible to our target distribution $p(z|x)$.\\
\newline
The most prominent divergence measure used in statistics is the Kullback-Leibler (KL) divergence:
\begin{equation}
KL(p||q) := \int q(\theta)\log\left(\frac{q(\theta)}{p(\theta|y)}\right) d\theta
\label{eq:KL_div}
\end{equation}
It has been introduced by Kulback and Leibler in 1951, who described it as a "directed divergence" as it is asymmetric, \textit{i.e. }$KL(p||q) \neq KL(q||p)$.\\
\newline
We try to optimize the family of densities over latent variables, parametrized by variational parameters. Finding the best suitable family is finding the best settings of parameters closest to the desired distribution w.r.t. KL. We are looking for $\mathcal{D}$ flexible enough for the approximation $q \in \mathcal{D}$ to be close $p(z|x)$ w.r.t. the $KL$ divergence but simple enough for efficient optimization.\\

\begin{equation}
q^*(z) = \arg\min_{q(z) \in \mathcal{D}} KL(q(z)||p(z|x))
\label{eq:best_q}
\end{equation}
Now, minimizing the KL divergence can be complicated depending on the density we want to approximate and the densities family $\mathcal{D}$ we want $q$ to be apart of. To ease the calculations, we will use the evidence lower bound.
\subsection{Evidence Lower Bound (ELBO)}

Assume $\mathcal{D}$ a density family, $q(z) \in \mathcal{D}$ a candidate approximation for $p(z|x)$. We have:
\begin{align}
KL(q(z)||p(z|x)) &= \mathbb{E}\left[\log q(z)\right] - \mathbb{E}\left[\log p(z|x)\right]\\
&= \mathbb{E}\left[\log q(z)\right] - \mathbb{E}\left[\log p(z,x)\right] + \log p(x)
\label{eq:KL_to_logP}
\end{align}
We call the evidence lower bound (ELBO) :
\begin{equation}
ELBO(q) = \mathbb{E}\left[\log p(z,x)\right] - \mathbb{E}\left[\log q(z)\right]
\label{eq:ELBO}
\end{equation}
which means that:
\begin{equation}
KL(q||p) = \log p - ELBO(q)
\label{eq:ELBO-KL}
\end{equation}
Now, we can see that when optimizing on $q$, the term $\log p$ has no influence on the optimum. Hence, minimizing the KL divergence w.r.t. $q$ is equivalent to maximizing the ELBO w.r.t. $q$.\\
\newline
We have :
\begin{equation}
\log p(x) = \underbrace{KL(q||p)}_{\geq 0} + ELBO(q) \Rightarrow \log p(x) \geq ELBO(q)
\label{eq:ELBO+KL}
\end{equation}
Hence, $ELBO(q)$ is indeed a lower bound for the $\log p(x)$.